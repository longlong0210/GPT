import os
import google.generativeai as genai
import fitz  # PyMuPDF
import docx
import openpyxl
from pptx import Presentation

# ==========================
# 1. C·∫•u h√¨nh Google AI
# ==========================
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    GOOGLE_API_KEY = "AIzaSyABLonsDEQ7veJFWZf6lLlHvtPw9K4lBMs"  

genai.configure(api_key=GOOGLE_API_KEY)
print("‚úÖ ƒê√£ c·∫•u h√¨nh Google AI th√†nh c√¥ng.")


# ==========================
# 2. H√†m tr√≠ch xu·∫•t n·ªôi dung
# ==========================
def extract_text_from_pdf(file_path):
    text = ""
    with fitz.open(file_path) as doc:
        for page in doc:
            text += page.get_text()
    return text

def extract_text_from_docx(file_path):
    doc = docx.Document(file_path)
    return "\n".join([p.text for p in doc.paragraphs])

def extract_text_from_pptx(file_path):
    prs = Presentation(file_path)
    texts = []
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                texts.append(shape.text)
    return "\n".join(texts)

def extract_text_from_xlsx(file_path):
    wb = openpyxl.load_workbook(file_path)
    texts = []
    for sheet in wb.sheetnames:
        ws = wb[sheet]
        for row in ws.iter_rows():
            row_data = [str(cell.value) for cell in row if cell.value]
            if row_data:
                texts.append(" ".join(row_data))
    return "\n".join(texts)

def extract_text_from_txt(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()

# Mapping ƒë·ªãnh d·∫°ng file -> h√†m x·ª≠ l√Ω
extractors = {
    ".pdf": extract_text_from_pdf,
    ".docx": extract_text_from_docx,
    ".pptx": extract_text_from_pptx,
    ".xlsx": extract_text_from_xlsx,
    ".txt": extract_text_from_txt
}

def read_file_content(file_path):
    """T·ª± ph√°t hi·ªán lo·∫°i file v√† ƒë·ªçc n·ªôi dung"""
    if not os.path.exists(file_path):
        return f"L·ªói: File '{file_path}' kh√¥ng t·ªìn t·∫°i."
    
    ext = os.path.splitext(file_path)[1].lower()
    if ext in extractors:
        try:
            return extractors[ext](file_path)
        except Exception as e:
            return f"L·ªói khi ƒë·ªçc file {file_path}: {e}"
    else:
        return f"L·ªói: ƒê·ªãnh d·∫°ng file '{ext}' ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£."

# ==========================
# 3. G·ªçi Google AI
# ==========================
def analyze_files_with_gemini(file_paths, user_prompt):
    """ƒê·ªçc nhi·ªÅu file v√† g·ª≠i n·ªôi dung cho Google AI"""
    combined_text = ""
    for file_path in file_paths:
        content = read_file_content(file_path)
        if content.startswith("L·ªói:"):
            print(content)
            continue
        combined_text += f"\n\n--- N·ªôi dung t·ª´ file {os.path.basename(file_path)} ---\n{content}"

    if not combined_text.strip():
        return "Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ ph√¢n t√≠ch."

    model = genai.GenerativeModel("gemini-2.5-flash")
    prompt = f"{user_prompt}\n\nD·ªØ li·ªáu t·ª´ c√°c file:\n{combined_text}"

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"L·ªói khi g·ªçi Google AI: {e}"

# ==========================
# 4. Ch·∫°y th·ª≠
# ==========================
if __name__ == "__main__":
    # V√≠ d·ª• t·∫°o file test
    with open("test.txt", "w", encoding="utf-8") as f:
        f.write("Ch√≥ l√† ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh trung th√†nh, lu√¥n ch√†o ƒë√≥n ta b·∫±ng chi·∫øc ƒëu√¥i v·∫´y kh√¥ng ng·ª´ng. Ch√∫ng mang l·∫°i ni·ªÅm vui v√¥ b·ªù b·∫øn.")

    doc = docx.Document()
    doc.add_paragraph("V·ªõi b·ªô l√¥ng m·ªÅm m∆∞·ª£t v√† ƒë√¥i m·∫Øt tinh anh, ch√≥ l√† ng∆∞·ªùi v·ªá sƒ© ƒë√°ng tin c·∫≠y cho gia ƒë√¨nh. Ch√∫ng r·∫•t th√¥ng minh v√† v√¥ c√πng d≈©ng c·∫£m.")
    doc.save("test.docx")

    files = ["test.txt", "test.docx"]
    prompt = "H√£y t√≥m t·∫Øt n·ªôi dung ch√≠nh c·ªßa t·∫•t c·∫£ t√†i li·ªáu n√†y."
    
    print("\nüîç ƒêang ph√¢n t√≠ch nhi·ªÅu file...")
    result = analyze_files_with_gemini(files, prompt)
    print("\n‚úÖ K·∫øt qu·∫£ t·ª´ Google AI:\n", result)
