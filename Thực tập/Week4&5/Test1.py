import os
import gradio as gr
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage
from langchain_core.documents import Document

# --- PH·∫¶N 1: C·∫§U H√åNH V√Ä KH·ªûI T·∫†O C√ÅC TH√ÄNH PH·∫¶N C·ªêT L√ïI ---

# C·∫•u h√¨nh API Key c·ªßa Google AI
# ƒê·ªÉ an to√†n, h√£y ƒë·∫∑t API key c·ªßa b·∫°n v√†o bi·∫øn m√¥i tr∆∞·ªùng.
try:
    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
    if not GOOGLE_API_KEY:
        # Thay th·∫ø b·∫±ng API key c·ªßa b·∫°n ·ªü ƒë√¢y n·∫øu kh√¥ng ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng
        GOOGLE_API_KEY = "AIzaSyABLonsDEQ7veJFWZf6lLlHvtPw9K4lBMs"
        print("C·∫£nh b√°o: API Key ƒë∆∞·ª£c ƒë·∫∑t tr·ª±c ti·∫øp trong code.")
    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY
    print("ƒê√£ c·∫•u h√¨nh Google AI API Key th√†nh c√¥ng.")
except Exception as e:
    print(f"L·ªói c·∫•u h√¨nh API Key: {e}")

# Kh·ªüi t·∫°o c√°c m√¥ h√¨nh (t·∫£i m·ªôt l·∫ßn ƒë·ªÉ ti·∫øt ki·ªám th·ªùi gian)
print("ƒêang t·∫£i c√°c m√¥ h√¨nh AI...")
embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)
print("T·∫£i m√¥ h√¨nh th√†nh c√¥ng!")

# --- PH·∫¶N 2: C√ÅC H√ÄM X·ª¨ L√ù CHO GRADIO ---

def create_chatbot(knowledge_base_text):
    """
    X√¢y d·ª±ng chatbot t·ª´ vƒÉn b·∫£n ki·∫øn th·ª©c do ng∆∞·ªùi d√πng cung c·∫•p.
    """
    if not knowledge_base_text or knowledge_base_text.strip() == "":
        return None, "Vui l√≤ng nh·∫≠p c∆° s·ªü ki·∫øn th·ª©c tr∆∞·ªõc khi x√¢y d·ª±ng."

    # Chuy·ªÉn vƒÉn b·∫£n th√¥ th√†nh ƒë·ªëi t∆∞·ª£ng Document c·ªßa LangChain
    documents = [Document(page_content=knowledge_base_text)]

    # Ph√¢n ƒëo·∫°n vƒÉn b·∫£n
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = text_splitter.split_documents(documents)

    # T·∫°o embedding v√† Vector DB
    vector_db = FAISS.from_documents(chunks, embeddings)

    # T·∫°o retriever
    retriever = vector_db.as_retriever()

    # --- B·∫ÆT ƒê·∫¶U PH·∫¶N THAY ƒê·ªîI ---
    # T·∫°o prompt ƒë·ªÉ bi·∫øn c√¢u h·ªèi n·ªëi ti·∫øp th√†nh c√¢u h·ªèi ƒë·ªôc l·∫≠p
    contextualize_q_system_prompt = (
        "Given a chat history and the latest user question "
        "which might reference context in the chat history, "
        "formulate a standalone question which can be understood "
        "without the chat history. Do NOT answer the question, "
        "just reformulate it if needed and otherwise return it as is."
    )
    contextualize_q_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", contextualize_q_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )
    history_aware_retriever = create_history_aware_retriever(
        llm, retriever, contextualize_q_prompt
    )

    # T·∫°o prompt ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi cu·ªëi c√πng d·ª±a tr√™n ng·ªØ c·∫£nh
    qa_system_prompt = (
        "You are an assistant for question-answering tasks. "
        "Use the following pieces of retrieved context to answer "
        "the question. If you don't know the answer, just say "
        "that you don't know. Use three sentences maximum and keep the "
        "answer concise."
        "\n\n"
        "{context}"
    )
    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", qa_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    # T·∫°o chu·ªói x·ª≠ l√Ω t√†i li·ªáu
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    
    # K·∫øt h·ª£p t·∫•t c·∫£ l·∫°i th√†nh chu·ªói RAG cu·ªëi c√πng
    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
    
    return rag_chain, "Chatbot ƒë√£ s·∫µn s√†ng! B·∫°n c√≥ th·ªÉ b·∫Øt ƒë·∫ßu ƒë·∫∑t c√¢u h·ªèi."

def handle_user_query(user_input, chat_history, chatbot_chain):
    """
    X·ª≠ l√Ω c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi.
    """
    if chatbot_chain is None:
        return "", chat_history + [[user_input, "L·ªói: Vui l√≤ng x√¢y d·ª±ng chatbot tr∆∞·ªõc."]]

    # Chuy·ªÉn ƒë·ªïi l·ªãch s·ª≠ chat c·ªßa Gradio sang ƒë·ªãnh d·∫°ng c·ªßa LangChain
    chat_history_for_chain = []
    for human, ai in chat_history:
        chat_history_for_chain.append(HumanMessage(content=human))
        chat_history_for_chain.append(ai) # Gradio l∆∞u AIMessage d∆∞·ªõi d·∫°ng str

    # L·∫•y c√¢u tr·∫£ l·ªùi t·ª´ chu·ªói RAG
    response = chatbot_chain.invoke({
        "input": user_input,
        "chat_history": chat_history_for_chain
    })
    
    # C·∫≠p nh·∫≠t l·ªãch s·ª≠ chat c·ªßa Gradio
    chat_history.append([user_input, response['answer']])
    
    return "", chat_history
# --- K·∫æT TH√öC PH·∫¶N THAY ƒê·ªîI ---

# --- PH·∫¶N 3: X√ÇY D·ª∞NG GIAO DI·ªÜN GRADIO ---

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    # L∆∞u tr·ªØ ƒë·ªëi t∆∞·ª£ng chatbot chain gi·ªØa c√°c l·∫ßn g·ªçi
    chatbot_state = gr.State()

    gr.Markdown("# ü§ñ Chatbot H·ªèi-ƒê√°p Th√¥ng Minh (RAG)")
    gr.Markdown("Nh·∫≠p t√†i li·ªáu c·ªßa b·∫°n v√†o √¥ b√™n d∆∞·ªõi, nh·∫•n 'X√¢y d·ª±ng Chatbot', sau ƒë√≥ b·∫Øt ƒë·∫ßu cu·ªôc tr√≤ chuy·ªán.")

    with gr.Row():
        with gr.Column(scale=1):
            knowledge_box = gr.Textbox(
                lines=20,
                label="C∆° s·ªü ki·∫øn th·ª©c",
                placeholder="D√°n n·ªôi dung vƒÉn b·∫£n c·ªßa b·∫°n v√†o ƒë√¢y..."
            )
            build_button = gr.Button("X√¢y d·ª±ng Chatbot", variant="primary")
            status_display = gr.Markdown("")

        with gr.Column(scale=2):
            chatbot_display = gr.Chatbot(label="H·ªôp tho·∫°i Chat", height=500)
            query_box = gr.Textbox(
                label="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n",
                placeholder="V√≠ d·ª•: Th·ªß ƒë√¥ c·ªßa Ph√°p l√† g√¨?"
            )
            submit_button = gr.Button("G·ª≠i")

    # X·ª≠ l√Ω s·ª± ki·ªán
    build_button.click(
        fn=create_chatbot,
        inputs=[knowledge_box],
        outputs=[chatbot_state, status_display]
    )

    query_box.submit(
        fn=handle_user_query,
        inputs=[query_box, chatbot_display, chatbot_state],
        outputs=[query_box, chatbot_display]
    )
    
    submit_button.click(
        fn=handle_user_query,
        inputs=[query_box, chatbot_display, chatbot_state],
        outputs=[query_box, chatbot_display]
    )

# --- PH·∫¶N 4: CH·∫†Y ·ª®NG D·ª§NG ---
if __name__ == "__main__":
    demo.launch(debug=True)
