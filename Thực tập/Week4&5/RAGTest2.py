import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
import os
import textwrap
import gradio as gr

# --- PHáº¦N 1: Cáº¤U HÃŒNH GOOGLE AI ---
try:
    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
    if not GOOGLE_API_KEY:
        GOOGLE_API_KEY = "AIzaSyABLonsDEQ7veJFWZf6lLlHvtPw9K4lBMs"  # Thay báº±ng API key cá»§a báº¡n
        print("âš ï¸ Cáº£nh bÃ¡o: API Key Ä‘ang Ä‘Æ°á»£c Ä‘áº·t trá»±c tiáº¿p trong code.")
    genai.configure(api_key=GOOGLE_API_KEY)
    print("âœ… ÄÃ£ cáº¥u hÃ¬nh Google AI thÃ nh cÃ´ng.")
except Exception as e:
    print(f"âŒ Lá»—i cáº¥u hÃ¬nh Google AI: {e}")


# --- PHáº¦N 2: Há»† THá»NG RAG ---
class RAGSystem:
    def __init__(self, corpus, embedding_model_name='bkai-foundation-models/vietnamese-bi-encoder'):
        print("ğŸš€ Äang khá»Ÿi táº¡o há»‡ thá»‘ng RAG...")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        self.generation_model = genai.GenerativeModel('gemini-2.5-flash')
        self.vector_db, self.chunks = self._build_vector_db(corpus)
        print("âœ… Há»‡ thá»‘ng RAG Ä‘Ã£ sáºµn sÃ ng.")

    def _build_vector_db(self, corpus):
        text_splitter = textwrap.TextWrapper(width=200, break_long_words=False, replace_whitespace=False)
        chunks = text_splitter.wrap(corpus)
        print(f"ğŸ“„ TÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh {len(chunks)} Ä‘oáº¡n.")

        print("ğŸ”„ Äang táº¡o vector embedding...")
        chunk_embeddings = self.embedding_model.encode(chunks, convert_to_tensor=True, show_progress_bar=False)
        chunk_embeddings = chunk_embeddings.cpu().numpy()

        d = chunk_embeddings.shape[1]
        index = faiss.IndexFlatL2(d)
        index.add(chunk_embeddings)
        print("ğŸ“¦ ÄÃ£ xÃ¢y dá»±ng xong Vector DB.")
        return index, chunks

    def retrieve(self, query, k=3):
        query_embedding = self.embedding_model.encode([query])
        _, indices = self.vector_db.search(query_embedding, k)
        return [self.chunks[i] for i in indices[0]]

    def generate(self, relevant_chunks, query):
        context = "\n\n".join(relevant_chunks)
        prompt = f"""
        Dá»±a vÃ o ngá»¯ cáº£nh dÆ°á»›i Ä‘Ã¢y, hÃ£y tráº£ lá»i cÃ¢u há»i má»™t cÃ¡ch tá»± nhiÃªn, chÃ­nh xÃ¡c.
        Náº¿u thÃ´ng tin khÃ´ng cÃ³ trong ngá»¯ cáº£nh, hÃ£y nÃ³i rÃµ Ä‘iá»u Ä‘Ã³.

        **Ngá»¯ cáº£nh:**
        {context}

        **CÃ¢u há»i:**
        {query}

        **CÃ¢u tráº£ lá»i:**
        """
        response = self.generation_model.generate_content(prompt)
        return response.text

    def ask(self, query):
        retrieved_chunks = self.retrieve(query)
        return self.generate(retrieved_chunks, query)


# --- PHáº¦N 3: HÃ€M Xá»¬ LÃ GRADIO ---
def rag_answer(corpus, question):
    if not corpus.strip():
        return "âš ï¸ Vui lÃ²ng nháº­p vÄƒn báº£n corpus."
    if not question.strip():
        return "âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i."

    rag_system = RAGSystem(corpus)
    return rag_system.ask(question)


# --- PHáº¦N 4: GIAO DIá»†N GRADIO ---
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ” RAG QA vá»›i Google Gemini + FAISS + SentenceTransformer")
    corpus_input = gr.Textbox(label="ğŸ“„ VÄƒn báº£n Corpus", placeholder="Nháº­p ná»™i dung vÄƒn báº£n cá»§a báº¡n", lines=8)
    question_input = gr.Textbox(label="â“ CÃ¢u há»i", placeholder="Nháº­p cÃ¢u há»i", lines=2)
    output_box = gr.Textbox(label="ğŸ¤– CÃ¢u tráº£ lá»i", lines=6)

    submit_btn = gr.Button("ğŸš€ Truy váº¥n RAG")
    submit_btn.click(fn=rag_answer, inputs=[corpus_input, question_input], outputs=output_box)

demo.launch()
